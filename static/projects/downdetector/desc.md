The Down Detector was a project commissioned for me by Local Search Appeal in order to solve the visibility problem that they suffered with their websites. Before the Down Detector, they would only know that a site was down after receiving user complaints, which was often days or weeks after the actual outage had occurred and cost an untold amount in lost revenue. Beyond that, manual administration at the company meant that at certain times, phone numbers were being paid for but not being used,alongside other issues. 

To solve this, Down Detector was created as a generalized hub to inform the company of any outages with any of their main services. Interfacing with a MySQL database, Down Detector maintained a list of all issues that it could monitor throughout the company, alongside when they first occurred.

The main heart of Down Detector was a cronjob on a single-core Ubuntu machine that would run our monitoring service. Based on a web-scraped copy of every domain the company needed to keep track of, more web scraping was performed on each site to check for outages or errors within commonly used site pages. Additionally, Down Detector interacted with the Call Tracking Metrics API to see if there were any potentially dormant accounts that might indicate an issue elsewhere within the company. Once any new changes had been added to the database, a list of any newfound issues would be sent via email to myself and our operations lead.